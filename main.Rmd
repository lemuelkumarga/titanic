---
title: "Estimating Survival Rate of Titanic Passengers"
author: "Lemuel Kumarga"
always_allow_html: yes
knit: (function(inputFile, encoding) { source("shared/knit.R"); knitter(inputFile, encoding)})
---

```{r echo=FALSE, warning=FALSE, results='hide'}
options(warn=-1)

packages <- c("knitr")
tmp <- lapply(packages, library, character.only = TRUE)
read_chunk("main.R")
read_chunk("shared/helper.R")
  
```

## Problem Description

Set for its maiden voyage in 1912, RMS Titanic was then considered unsinkable due to its robust structure. After picking up passengers in Southampton, Cherbourg and Queenstown, the ship set sail towards New York. It was on their way there that the Titanic met its calamitous fate, crashing into an Iceberg and rendering more than 50% of the passengers lost.

There were many questions concerning the events leading to and during the disaster. Some of these include: Which part of the ship was most damaged? What was the evacuation process of the passengers? Using data containing the personal details and disaster outcomes (survival/lost) of passengers, we aim to <b>discover the various factors affecting the survival likelihood of passengers.</b> 

<span class="color-1-text">FYI: This problem was posed as an introductory challenge in <a href="https://www.kaggle.com/c/titanic" target="_blank">Kaggle</a>. The passengers are divided into two sets, one used for training and the other for testing. The training sets contain both the personal details of passengers and their outcomes, while the testing set only contain the former. By developing a robust model through the training set, we hope to predict the survival likelihood of passengers in the testing set.</span>

## Summary of Results

To be completed.

## Preliminaries

First load the necessary packages for this exercise.
```{r}
<<init>>

si <- sessionInfo()
base_pkg_str <- paste0("Base Packages: ",paste(si[["basePkgs"]], collapse=", "))
attached_pkg_str <- paste0("Attached Packages: ",paste(names(si[["otherPkgs"]]), collapse=", "))
cat(paste0(base_pkg_str,"\n",attached_pkg_str))
```

## Exploration

### About the Data

We kick off by exploring the data that was provided:
```{r}
<<data_overview>>
  
<<data_comp>>

pander(cols_summary, caption='Titanic Passengers Data - For more info, please visit <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Kaggle</a>')
```
<br>

Based on the above table, notice the following:

* <span class="hl color-1-text">Names</span> are aggregated in the following format: <span class="hl color-2-text">Last_Name, Title 
First_Name</span>.
* <span class="hl color-1-text">Passenger class (Pclass) </span> levels are the equivalent of <span class="hl color-2-text">First Class (1), Business Class (2) and Economy Class (3)</span>. Hence, they could be used as an indicator of income level.
* <span class="hl color-1-text">Age</span> has missing data to be populated.
* <span class="hl color-1-text">Cabin</span> data is sparse, and hence we may want to exclude this for the prediction model.

### Preliminary Insights

<div class="st">Insight 1: Wealthy individuals are more likely to survive.</div>

Using passenger class as a proxy for wealth, we calculated the survival likelihood (% of passengers survived) for each class.
```{r exp_income, fig.height=3, fig.width=10, fig.align="center"}

```
The chart above shows that the more premium the class, the more likely the passengers were to survive. One potential reason explaining this insight could be that 1st class passengers were the first in line to access the lifeboats, while 3rd class passengers were left to fend for themselves.

```{r exp_fare, fig.height=3, fig.width=10, fig.align="center"}

```
Similarly, we also noticed this phenomenon in fares, where the higher amount an individual paid for the fares, the more likely he/she will survive the crash.

<div class="st">Insight 2: Females and more esteemed individuals are more likely to survive than males.</div>

The data provides us with a list of titles under the <span class="color-1-text">Name</span> column. Each title is associated with a gender (with the exception of one), as shown below:

```{r exp_titles, fig.height=2.6, fig.width=10, fig.align="center"}

```

Other than <span class="hl color-1-text">Mr, Miss, Mrs and Master</span>, all other titles are not presumed by many passengers. To navigate the small sample size, we group all of these other titles under <span class="hl color-2-text">Rare Title</span>.

Using the following modifications, we can then assess the survival likelihood of each title and gender:

```{r exp_title_gender, fig.height=3, fig.width=10, fig.align="center"}

```

<span class="hl">All</span> females, regardless of their titles, have higher survival likelihoods than males. In addition, having a title other than Mrs, Miss or Mr, elevates the survival likelihood of the individual. One reason explaining this insight could be that females and esteemed individuals were given early access to escape the Titanic. 

<div class="st">Insight 3: The younger the passenger, the more likely he/she will survive.</div>

The chart below shows how survival likelihood changes according to age.

```{r exp_age, fig.height=3, fig.width=10, fig.align="center"}

```

With the limited data set, we can see that younger individuals are more likely to survive. A possible explanation is probably because babies and toddlers occupy less space (and hence easier to find seats within the lifeboats). 

However, older people, especially those more than 60 years old, are less likely to survive. This is probably due to their lack of agility in responding to the crash. 

<div class="st">Insight 4: An individual is more likely to survive if he/she has other family members with him/her.</div>

Typically, we would expect that the more family members there is in Titanic, the less likely an individual will survive. This is because individuals would likely go into lifeboats with their family members, making it harder to find space in the lifeboats.

However, contrary to expectations, the data shows that the larger the family size (individual + siblings/spouses + parent/children), the more likely an individual is likely to survive:

```{r exp_company, fig.height=4, fig.width=10, fig.align="center"}

```

This counterintuitive relationship can be attributed to the following 3 factors:

* <span class="hl color-3-text">Child Privilege</span>: If you have a larger family size, there is an increased probability that you will be a child. For example, a family of 5 will more likely include 2 adults and 3 children, rather than 5 adults.
As children have a higher survival likelihood (from insight 3), by the transitive property, a larger family size consequently implies a higher likelihood of survival.The benefits accrued by this privilege, shown in <span class="hl color-3-text">red</span>, can be accounted for when we compare data from all passengers against data from only the adults (> 15 years old).

* <span class="hl color-2-text">Parental Privilege</span>: The larger the family size, the more likely you are to be a parent. Parents can utilize their children's lifeboat guarantee to tag-along and get themselves a space. These benefits, which are represented in <span class="hl color-2-text">green</span>, surface when we compare the survival likelihoods of adults with children and adults with none.

* <span class="hl color-1-text">Husband Privilege</span>: As a male, having a family size of 2 and no children may guarantee you better odds of being in the lifeboat, since you can utilize your wife's lifeboat premium (see Insight 2) to find a space for yourself. These benefits, shown in <span class="hl color-1-text">blue</span>, can be accounted for when we compare between males and females that do not have children.

<div class="st">Insight 5: Cabin positions should have an impact of survivalhood, but only to a certain extent.</div>

Cabins further away from the lifeboats will have a more difficult time surviving, hence we should assume that where passengers stay will have an impact on their survivalhood. However, the cabin positions can only determine survivalhood partially, given that passengers may not be at their cabins during the time of crash.

A more detailed deck plan can be found <a href="https://www.encyclopedia-titanica.org/titanic-deckplans/b-deck.html" target="_blank">here</a>. As can be seen, the letter of the cabin represents the deck (floor) where the room is located. We also see that odd numbers correspond to one side of the Titanic, while even numbers correspond to the other.

We will break down the cabin position into three constituents: the cabin floor, the cabin number (odd or even), and the number of cabins specified.

```{r exp_cabin_decompose}

```

##### Cabin Floors

```{r exp_cabin_floors, fig.height=5, fig.width=7, warning=FALSE, fig.align="center"}

```

From the chart, we can deduce that <span class="hl color-1-text">Cabins B to E</span> has a higher likelihood of survival compared to other/unspecified cabins, which suggests that the position of cabins play a role in determining whether a passenger survive.

##### Cabin Numbers

```{r exp_cabin_number, fig.height=3, fig.width=10, fig.align="center"}

```

It is pretty clear that those who stay in the odd rooms are more likely to survive than those in the even rooms.

In conclusion, cabin floors and cabin numbers, when available, can determine a passenger's survival likelihood.

<div class="st">Insight 6: Port of embarkation has an impact on survivalhood, as they are correlated with Passenger class.</div>

```{r exp_port, fig.height = 3, fig.align="center"}

```

<br>
At first glance, there seems to be no plausible explanation why a passenger's port of embarkation will have an impact on the passenger's survival likelihood.

```{r exp_port_income, fig.height = 3, fig.width=10, fig.align="center"}

```

However, by studying the demographics of the passengers who embarked at each port, we know that a higher proportion of Cherbough are high-income. This explains the higher survival likelihood for those who embarked at Cherbough.

## Modeling Survival Likelihood

### Rationale

While the preliminary insights are useful in qualitatively determining factors influencing survival likelihood, we also need to have a way to quantify the importance for each factor. Building a predictive model would achieve that goal.

Since this is a classification problem (for each passenger, we either group them as "Survived" or "Died"), models such as logistic regression and decision trees come to mind. However, for the purposes of this study, the <a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank">Random Forest</a> algorithm was used, as it is more rebust and there already exists a useful function <code>importance</code> that can assess the various factors intuitively.

### Preparation

#### Variables Considered

Based on the above insights, we will be adding the following factors to predict the survival likelihood of an individual.

Feature | Variable Type | Insights Supporting the Feature 
- | - | -
Pclass | Continuous | Insight 1
Fare | Continuous | Insight 1
Sex | Categorical | Insight 2
Title | Categorical | Insight 2
Age | Continuous | Insight 3
FamilySize | Continuous | Insight 4

*Initially, CabinFloor, CabinNumber and Port of Embarkation were used as predictors of survival likelihood. However, the accuracy of the model fell with the inclusion of these features due to over-fitting. This implies that we may be over-inflating the impact of embarkation port, while the cabin data is too sparse to yield any useful information.

#### Populating Age
Before using the raw data as an input to the model, we have to ensure that the data is in a well-defined state. One of the first things we have to do is to populate any unidentified <span class="hl">Age</span> values.

```{r, echo=FALSE}
<<model_age_append>>

<<model_age_vars>>
```

We will use the following variables as predictors of Age:

* <span class="hl color-1-text">Pclass</span>: 1st class members (`r round(age_by[['Pclass']][[1]])` years old on average) are generally older than 2nd (`r round(age_by[['Pclass']][[2]])`) or 3rd (`r round(age_by[['Pclass']][[3]])`) class members.

* <span class="hl color-1-text">Title</span>: Masters (`r round(age_by[['Title']][['Master']])` years old on average) and Miss-es (`r round(age_by[['Title']][['Miss']])`) tend to be younger than Mr (`r round(age_by[['Title']][['Mr']])`) and Mrs (`r round(age_by[['Title']][['Mrs']])`).

* <span class="hl color-1-text">ConfirmedAdult</span>: This is a new category created just to predict the age. Assuming that there are negligible intergenerational families in Titanic (i.e. an individual having both parents and children), we know that having more than 2 parent-children relationships strongly implies an individual is a parent (since a child can have a maximum of 2 parent relationships). Such individuals are what we tag as ConfirmedAdults. These passengers are `r round(age_by[['ConfirmedAdult']][['1']] - age_by[['ConfirmedAdult']][['0']])` years older on average than the rest of the passengers.

* <span class="hl color-1-text">FamilySize</span>: Based on Insight 4, we know that a larger family size implies a higher probability of being a child (or in other words, a younger age). In fact, the correlation between age and family size is modest at `r round(cor(age_data$FamilySize, age_data$Age)*100)`%.

We will use ANOVA regression to predict Age based on the factors above. ANOVA regression is similar to a linear regression, with the added capability of regressing over categorical variables. 

Listed below is the summary of the ANOVA regression.

```{r}
<<model_age_append>>

<<model_age_anova>>
```

Due to our careful selection of variables, all of the coefficients are statistically significant under a 5% significance level. This suggests that the variables are all good predictors of Age.

#### Populating Others

Other than age, we also need some kind of sanity checks to ensure that all data has been populated. Since the rest of the data is either too varied, or require only a small set of missing values to be filled, we will populate those columns with category "Unknown" or the number -1.

#### Putting It All Together

After resolving the missing data, we can now create a process that takes in the raw data and output a cleaned data for model consumption.

Below is an example of the data after cleansing:

```{r}

<<model_cleanse>>
  
pander(head(cleaned_set))

```


### The Model

Prior to constructing the random forest model, we need to split the training set into two groups, one for training purposes and the other for testing purposes. 

In order to do so, let us first shuffle the training data and split the dataset in a 80%-20% partition. The larger partition will then be used to construct a random forest model.

```{r model_randomize}

```

Listed below is a summary of the Random Forest model.

```{r model_construct}

rf_model

```

#### Assessing Performance

The out-of-bag error, a measure of model accuracy, indicates that the model will identify survivors accurately `r round((1 - median(rf_model$err.rate[,1]))*100,0)`% of the time.

```{r model_internal_test}
```

Using the 20% testing group, we find that the model predicted accurately `r round((1 - cmp$err / cmp$size) * 100,1)`% of the time!

Let us now reconstruct the model using all the training set, and save the predictions of Kaggle's testing set for <a href="https://www.kaggle.com/c/titanic/submit" target="_blank">submission</a>.

```{r model_external_test}
```

The model performed slightly lower to our expectations, predicting accurately 78.9% of the time (<25th percentile in <a href="https://www.kaggle.com/c/titanic/leaderboard" target="_blank">Kaggle Leaderboard</a> at the time of submission).  Since there is only an accuracy difference of 2-3% between our internal (using the 20% partition) and external (Kaggle's testing set) tests, we conclude that the model is not being overfitted. 

#### Assessing Factors
